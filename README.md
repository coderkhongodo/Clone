# ğŸ¯ CLICKBAIT DETECTION PROJECT

Dá»± Ã¡n phÃ¡t hiá»‡n clickbait sá»­ dá»¥ng 3 model chÃ­nh trÃªn dataset `simple_dataset`.

## ğŸ“Š **Cáº¤U TRÃšC Dá»° ÃN**

```
ğŸ“ NCKH/
â”œâ”€â”€ ğŸ“Š simple_dataset/          # Dá»¯ liá»‡u gá»‘c (train/val/test)
â”œâ”€â”€ ğŸ“Š data_alpaca_v2/         # Dá»¯ liá»‡u Alpaca format tá»« simple_dataset
â”œâ”€â”€ ğŸ† evaluation_results/      # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ cÃ¡c models
â”œâ”€â”€ ğŸ¤– models/                  # CÃ¡c models Ä‘Ã£ train
â”‚   â”œâ”€â”€ phobert/               # PhoBERT models + data
â”‚   â”œâ”€â”€ tfidf_svm/             # TF-IDF SVM models
â”‚   â””â”€â”€ vistral/               # Vistral models
â”œâ”€â”€ ğŸ“ scripts/                 # Scripts theo tá»«ng model
â”‚   â”œâ”€â”€ phobert/               # PhoBERT scripts
â”‚   â”œâ”€â”€ lstm/                  # LSTM scripts
â”‚   â”œâ”€â”€ tfidf_svm/             # TF-IDF SVM scripts
â”‚   â”œâ”€â”€ vistral/               # Vistral scripts
â”‚   â”œâ”€â”€ data_prep/             # Data preparation scripts
â”‚   â””â”€â”€ train_launcher.py      # Training launcher
â””â”€â”€ ğŸ“‹ requirements.txt         # Dependencies
```

## ğŸ¤– **CÃC MODEL CHÃNH**

### 1. **PhoBERT** (BERT-based) ğŸ†
- **Models**: PhoBERT-base, PhoBERT-large
- **Location**: `models/phobert/checkpoints/`
- **Scripts**: `scripts/phobert/`
- **Best Performance**: PhoBERT-large (F1: 0.8290)

### 2. **LSTM Embedding** (Deep Learning)
- **Model**: LSTM vá»›i word embeddings
- **Performance**: F1-Score 0.7539
- **Approach**: Sequential neural network

### 3. **Vistral** (Large Language Model)
- **Models**: Few-shot fine-tune, Zero-shot fine-tune
- **Location**: `models/vistral/Vistral-v03/`
- **Scripts**: `scripts/vistral/`
- **Best Performance**: Few-shot (F1: 0.6898)

### 4. **TF-IDF + SVM** (Traditional ML)
- **Model**: TF-IDF Vectorizer + SVM Classifier
- **Location**: `models/tfidf_svm/models_tfidf_svm_v3/`
- **Scripts**: `scripts/tfidf_svm/`
- **Performance**: F1-Score 0.7426

## ğŸš€ **CÃCH Sá»¬ Dá»¤NG**

### **1. Chuáº©n bá»‹ dá»¯ liá»‡u**
```bash
# Convert simple_dataset sang Alpaca format
python scripts/data_prep/convert_simple_to_alpaca_v2.py

# Data augmentation (optional)
python scripts/data_prep/data_augmentation_synonym_only.py
```

### **2. PhoBERT**
```bash
# Preprocess data
python scripts/phobert/preprocess_for_phobert.py

# Train model
python scripts/phobert/train_phobert.py

# Evaluate model
python scripts/phobert/evaluate_phobert.py \
    --model_path models/phobert/checkpoints/phobert-large-v2/latest_checkpoint.pth \
    --model_name vinai/phobert-large \
    --data_path models/phobert/data-bert-v2/phobert-large-v2/test_processed.pkl
```

### **3. TF-IDF SVM**
```bash
# Train model
python scripts/tfidf_svm/train_tfidf_svm.py --data_dir simple_dataset

# Demo model
python scripts/tfidf_svm/demo_tfidf_svm.py
```

### **4. LSTM Embedding**
```bash
# Train LSTM model
python scripts/lstm/train_lstm_enhanced.py

# Evaluate LSTM model  
python scripts/lstm/run_lstm_enhanced.py
```

### **5. Vistral**
```bash
# Fine-tune model
python scripts/vistral/fine_tune_clickbait_vistral_v03.py

# Test model
python scripts/vistral/test_base_vistral.py
```

## ğŸ“ˆ **HIá»†U SUáº¤T MODELS**

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| **PhoBERT-large** | **0.8281** | **0.8301** | **0.8281** | **0.8290** |
| PhoBERT-base | 0.8223 | 0.8254 | 0.8223 | 0.8235 |
| Vistral (few-shot) | 0.7832 | 0.8092 | 0.6719 | 0.6898 |
| LSTM Embedding | 0.7559 | 0.7524 | 0.7559 | 0.7539 |
| TF-IDF + SVM | 0.7422 | 0.7431 | 0.7422 | 0.7426 |
| Vistral (zero-shot) | 0.3145 | 0.4275 | 0.4929 | 0.2510 |

### ğŸ† **Xáº¿p háº¡ng theo F1-Score:**
1. **PhoBERT-large**: 0.8290 â­
2. **PhoBERT-base**: 0.8235  
3. **LSTM Embedding**: 0.7539
4. **TF-IDF + SVM**: 0.7426
5. **Vistral (few-shot)**: 0.6898
6. **Vistral (zero-shot)**: 0.2510

### ğŸ“Š **PhÃ¢n tÃ­ch káº¿t quáº£:**
- **ğŸ¥‡ PhoBERT models** dáº«n Ä‘áº§u vá»›i F1-Score > 0.82, chá»©ng tá» sá»©c máº¡nh cá»§a pre-trained BERT
- **ğŸ¥ˆ LSTM Embedding** Ä‘áº¡t káº¿t quáº£ tá»‘t (0.7539) vá»›i approach Ä‘Æ¡n giáº£n hÆ¡n
- **ğŸ¥‰ TF-IDF + SVM** traditional ML váº«n competitive vá»›i 0.7426  
- **âš¡ Vistral few-shot** tá»‘t hÆ¡n zero-shot Ä‘Ã¡ng ká»ƒ (0.6898 vs 0.2510)
- **ğŸ“ˆ Precision cao nháº¥t**: Vistral few-shot (0.8092) - Ã­t false positive
- **ğŸ“ˆ Recall cÃ¢n báº±ng**: PhoBERT models cÃ³ recall tá»‘t nháº¥t

## ğŸ“‹ **YÃŠU Cáº¦U Há»† THá»NG**

```bash
pip install -r requirements.txt
```

## ğŸ† **ÄÃNH GIÃ MODELS**

Táº¥t cáº£ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c lÆ°u trong `evaluation_results/`:
- Confusion matrices
- Classification reports  
- Detailed metrics (JSON)
- Performance comparisons

## ğŸ‘¥ **TEAM & CONTRIBUTION**

Dá»± Ã¡n nghiÃªn cá»©u phÃ¡t hiá»‡n clickbait sá»­ dá»¥ng multiple approaches:
- Deep Learning (PhoBERT)
- Traditional ML (TF-IDF + SVM)  
- Large Language Models (Vistral)

---
**Cáº­p nháº­t cuá»‘i**: ÄÃ£ tÃ¡i cáº¥u trÃºc vÃ  tá»‘i Æ°u hÃ³a dá»± Ã¡n (Jul 2024) 