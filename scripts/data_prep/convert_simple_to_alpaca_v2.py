"""
Convert Simple Dataset to Alpaca Format V2
Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu t·ª´ simple_dataset sang format Alpaca JSON ƒë·ªÉ s·ª≠ d·ª•ng v·ªõi Vistral
"""

import pandas as pd
import json
import os
from tqdm import tqdm

def create_alpaca_format_v2(title, label):
    """
    T·∫°o format Alpaca V2 cho m·ªôt sample clickbait v·ªõi instruction t·ªëi ∆∞u cho Vistral
    """
    instruction = """B·∫°n l√† chuy√™n gia ph√¢n t√≠ch b√°o ch√≠ Vi·ªát Nam. H√£y ph√¢n lo·∫°i ti√™u ƒë·ªÅ b√†i b√°o th√†nh clickbait ho·∫∑c non-clickbait.

Ti√™u ch√≠ ph√¢n lo·∫°i:
- CLICKBAIT: Ti√™u ƒë·ªÅ c√¢u view, s·ª≠ d·ª•ng t·ª´ ng·ªØ c·∫£m x√∫c m·∫°nh, t·∫°o t√≤ m√≤ qu√° m·ª©c, thi·∫øu th√¥ng tin c·ª• th·ªÉ, c√≥ t·ª´ kh√≥a nh∆∞ "b√≠ m·∫≠t", "g√¢y s·ªëc", "kh√¥ng ai ng·ªù", "top X"
- NON-CLICKBAIT: Ti√™u ƒë·ªÅ th√¥ng tin r√µ r√†ng, kh√°ch quan, trung th·ª±c, c√≥ n·ªôi dung c·ª• th·ªÉ, mang t√≠nh tin t·ª©c th·ª±c t·∫ø

H√£y ph√¢n t√≠ch v√† ƒë∆∞a ra k·∫øt lu·∫≠n ch√≠nh x√°c."""

    input_text = f"Ph√¢n lo·∫°i ti√™u ƒë·ªÅ sau: {title}"
    
    # T·∫°o output v·ªõi ph√¢n t√≠ch ng·∫Øn g·ªçn nh∆∞ng r√µ r√†ng
    if label == "clickbait":
        output_text = f"ƒê√¢y l√† ti√™u ƒë·ªÅ clickbait v√¨ s·ª≠ d·ª•ng ng√¥n ng·ªØ c√¢u view v√† t·∫°o t√≤ m√≤ qu√° m·ª©c.\n\nK·∫øt qu·∫£: clickbait"
    else:
        output_text = f"ƒê√¢y l√† ti√™u ƒë·ªÅ non-clickbait v√¨ cung c·∫•p th√¥ng tin r√µ r√†ng v√† kh√°ch quan.\n\nK·∫øt qu·∫£: non-clickbait"
    
    return {
        "instruction": instruction,
        "input": input_text,
        "output": output_text
    }

def convert_simple_dataset_to_alpaca(data_dir, output_dir):
    """
    Convert simple_dataset to Alpaca JSON format
    """
    print(f"START: Converting {data_dir} to Alpaca V2 format...")
    print(f"üìÅ Output directory: {output_dir}")
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # File mappings t·ª´ simple_dataset structure
    splits = ['train', 'val', 'test']
    total_samples = 0
    
    for split in splits:
        csv_file = os.path.join(data_dir, split, f"{split}.csv")
        output_file = os.path.join(output_dir, f"{split}_alpaca.json")
        
        if os.path.exists(csv_file):
            print(f"\nDATA: Converting {split} split from {csv_file}")
            
            # Load CSV
            df = pd.read_csv(csv_file)
            print(f"SUCCESS: Loaded {len(df)} samples")
            
            # Show label distribution
            label_counts = df['label'].value_counts()
            print(f"STATS: Label distribution:")
            for label, count in label_counts.items():
                percentage = count / len(df) * 100
                print(f"   {label}: {count} ({percentage:.1f}%)")
            
            # Convert to Alpaca format
            alpaca_data = []
            for _, row in tqdm(df.iterrows(), total=len(df), desc=f"Converting {split}"):
                alpaca_sample = create_alpaca_format_v2(row['title'], row['label'])
                alpaca_data.append(alpaca_sample)
            
            # Save to JSON
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(alpaca_data, f, ensure_ascii=False, indent=2)
            
            print(f"SAVE: Saved {len(alpaca_data)} samples to {output_file}")
            total_samples += len(alpaca_data)
            
        else:
            print(f"WARNING: Warning: {csv_file} not found, skipping...")
    
    return total_samples

def show_conversion_summary(output_dir):
    """
    Hi·ªÉn th·ªã t·ªïng k·∫øt qu√° tr√¨nh convert
    """
    print(f"\nCOMPLETE: CONVERSION COMPLETED!")
    print(f"LOAD: Output directory: {output_dir}/")
    print(f"REPORT: Files created:")
    
    total_samples = 0
    for split in ['train', 'val', 'test']:
        json_file = os.path.join(output_dir, f"{split}_alpaca.json")
        if os.path.exists(json_file):
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"   SUCCESS: {json_file} - {len(data):,} samples")
                total_samples += len(data)
    
    print(f"STATS: Total samples converted: {total_samples:,}")
    
    # Show example t·ª´ test file
    test_file = os.path.join(output_dir, "test_alpaca.json")
    if os.path.exists(test_file):
        print(f"\nüìñ Example from test data:")
        with open(test_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if data:
                example = data[0]
                print(f"Input: {example['input']}")
                print(f"Output: {example['output']}")

def main():
    """
    Main conversion process
    """
    print("=" * 70)
    print("PROCESS: CONVERTING SIMPLE_DATASET TO ALPACA FORMAT V2")
    print("=" * 70)
    
    # Paths
    input_dir = "simple_dataset"
    output_dir = "data_alpaca_v2"
    
    # Validate input directory
    if not os.path.exists(input_dir):
        print(f"ERROR: Error: Input directory {input_dir} not found!")
        return
    
    print(f"üìÅ Input: {input_dir}")
    print(f"üìÅ Output: {output_dir}")
    
    # Convert
    total_samples = convert_simple_dataset_to_alpaca(input_dir, output_dir)
    
    # Show summary
    show_conversion_summary(output_dir)
    
    print(f"\nSUCCESS: Conversion completed successfully!")
    print(f"TARGET: Ready to use with test_base_vistral.py")
    print(f"   Update script to use: {output_dir}/test_alpaca.json")

if __name__ == "__main__":
    main() 