#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Launcher Script cho PhoBERT Training vá»›i VnCoreNLP Data
Script nÃ y giÃºp cháº¡y training vá»›i dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ báº±ng VnCoreNLP
"""

import subprocess
import sys
import os
from datetime import datetime

def run_training(model_type='base', epochs=15, batch_size=32, use_wandb=False):
    """
    Cháº¡y training PhoBERT vá»›i VnCoreNLP data
    
    Args:
        model_type: 'base' hoáº·c 'large'
        epochs: Sá»‘ epochs
        batch_size: Batch size
        use_wandb: CÃ³ sá»­ dá»¥ng wandb logging khÃ´ng
    """
    # Cáº¥u hÃ¬nh model
    if model_type == 'base':
        model_name = 'vinai/phobert-base'
        output_dir = 'checkpoints-vncorenlp/phobert-base'
    else:
        model_name = 'vinai/phobert-large'
        output_dir = 'checkpoints-vncorenlp/phobert-large'
    
    print(f"ğŸš€ TRAINING PHOBERT-{model_type.upper()} Vá»šI VNCORENLP DATA")
    print("=" * 60)
    print(f"ğŸ“‚ Model: {model_name}")
    print(f"ğŸ’¾ Output: {output_dir}")
    print(f"ğŸ”§ Data: VnCoreNLP preprocessed")
    print(f"ğŸ“… Epochs: {epochs}")
    print(f"ğŸ“¦ Batch size: {batch_size}")
    print("=" * 60)
    
    # Kiá»ƒm tra dá»¯ liá»‡u cÃ³ tá»“n táº¡i khÃ´ng
    data_subdir = f'phobert-{model_type}'
    data_path = os.path.join('data-vncorenlp-v2', data_subdir)
    train_path = os.path.join(data_path, 'train_processed.pkl')
    
    if not os.path.exists(train_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u: {train_path}")
        print("ğŸ’¡ HÃ£y cháº¡y apply_vncorenlp_to_phobert.py trÆ°á»›c")
        return False
    
    # Táº¡o command
    cmd = [
        'python', 'train_phobert_vncorenlp.py',
        '--model_name', model_name,
        '--data_dir', 'data-vncorenlp-v2',
        '--output_dir', output_dir,
        '--epochs', str(epochs),
        '--batch_size', str(batch_size),
        '--learning_rate', '1e-5',
        '--weight_decay', '0.01',
        '--warmup_ratio', '0.15',
        '--scheduler', 'cosine',
        '--dropout_rate', '0.3',
        '--num_freeze_layers', '6',
        '--loss_type', 'f1',
        '--pooling_strategy', 'cls_mean',
        '--use_amp',
        '--use_ema',
        '--ema_decay', '0.9999',
        '--patience', '5',
        '--balance_data',
        '--balance_strategy', 'oversample',
        '--gradient_clipping', '1.0',
        '--seed', '42'
    ]
    
    # ThÃªm wandb náº¿u Ä‘Æ°á»£c yÃªu cáº§u
    if use_wandb:
        cmd.extend(['--use_wandb', '--wandb_project', 'phobert-vncorenlp'])
    
    # Táº¡o run name vá»›i timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_name = f"phobert-{model_type}_vncorenlp_{timestamp}"
    cmd.extend(['--run_name', run_name])
    
    print(f"ğŸ“ Command: {' '.join(cmd)}")
    print()
    
    try:
        # Cháº¡y training
        result = subprocess.run(cmd, check=True)
        print(f"\nâœ… Training PhoBERT-{model_type} hoÃ n thÃ nh thÃ nh cÃ´ng!")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ Lá»—i training PhoBERT-{model_type}: {e}")
        return False
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ Training PhoBERT-{model_type} bá»‹ há»§y bá»Ÿi user")
        return False

def main():
    print("ğŸ‡»ğŸ‡³ PHOBERT TRAINING LAUNCHER - VNCORENLP DATA")
    print("=" * 60)
    
    # Kiá»ƒm tra dá»¯ liá»‡u Ä‘Ã£ cÃ³ chÆ°a
    if not os.path.exists('data-vncorenlp-v2'):
        print("âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u VnCoreNLP!")
        print("ğŸ’¡ HÃ£y cháº¡y: python apply_vncorenlp_to_phobert.py")
        return
    
    print("Chá»n model Ä‘á»ƒ train:")
    print("1. PhoBERT-base (nháº¹ hÆ¡n, nhanh hÆ¡n)")
    print("2. PhoBERT-large (chÃ­nh xÃ¡c hÆ¡n, cháº­m hÆ¡n)")
    print("3. Cáº£ hai (train base trÆ°á»›c, sau Ä‘Ã³ large)")
    
    choice = input("\nNháº­p lá»±a chá»n (1/2/3): ").strip()
    
    # Cáº¥u hÃ¬nh training
    print("\n=== Cáº¤U HÃŒNH TRAINING ===")
    
    try:
        epochs = int(input("Sá»‘ epochs (default: 15): ") or "15")
        batch_size = int(input("Batch size (default: 32): ") or "32")
    except ValueError:
        print("âŒ Input khÃ´ng há»£p lá»‡, sá»­ dá»¥ng default values")
        epochs, batch_size = 15, 32
    
    use_wandb_input = input("Sá»­ dá»¥ng wandb logging? (y/n, default: n): ").strip().lower()
    use_wandb = use_wandb_input in ['y', 'yes', '1']
    
    print(f"\nğŸ“Š Cáº¥u hÃ¬nh:")
    print(f"   ğŸ•’ Epochs: {epochs}")
    print(f"   ğŸ“¦ Batch size: {batch_size}")
    print(f"   ğŸ“ˆ Wandb: {'Yes' if use_wandb else 'No'}")
    print(f"   ğŸ”§ Data source: VnCoreNLP preprocessed")
    
    confirm = input("\nBáº¯t Ä‘áº§u training? (y/n): ").strip().lower()
    if confirm not in ['y', 'yes', '1']:
        print("âŒ Training cancelled")
        return
    
    # Báº¯t Ä‘áº§u training
    if choice == '1':
        run_training('base', epochs, batch_size, use_wandb)
    elif choice == '2':
        run_training('large', epochs, batch_size, use_wandb)
    elif choice == '3':
        print("ğŸ”„ Training PhoBERT-base first...")
        success = run_training('base', epochs, batch_size, use_wandb)
        if success:
            print("\nğŸ”„ Training PhoBERT-large...")
            run_training('large', epochs, batch_size, use_wandb)
    else:
        print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡")

if __name__ == "__main__":
    main() 